{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artwork-style.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVo36LEVadnVITxPIcSucb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahshawaiz/artwork-style-prediction/blob/master/artwork_style.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBt-5EUKJViJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# activate kaggle, mount grdive, download/unzip dataset\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"shahshawaiz\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"476e4fb10eef6d9da79358d4df0db985\" # key from the json file\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "files = ['train_1.zip', 'train_2.zip', 'train_3.zip', 'train_4.zip', 'train_5.zip', 'train_6.zip', 'train_7.zip', 'train_8.zip', 'train_9.zip']\n",
        "for path in files:\n",
        "  path_dir = path.strip('.zip')\n",
        "  path_gdrive = '/content/drive/My Drive/Colab Notebooks/dataset/wikiart/train'\n",
        "\n",
        "  !kaggle competitions download -c painter-by-numbers -f \"$path\"\n",
        "  !unzip -qq \"$path\"\n",
        "  !mv -n \"$path_dir\"/ \"$path_gdrive\"/\n",
        "  !rm -rf \"$path\" \"$path_dir\"\n",
        "\n",
        "# drive.flush_and_unmount()   \n",
        "\n",
        "# # # extract zip\n",
        "# # # !unzip '/content/drive/My Drive/university/s3/lfi/project/data/train_1.zip'\n",
        "\n",
        "# from tensorflow.python.client import device_lib\n",
        "# print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6OLjy0AXSAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pkgs installation\n",
        "# !pip install tensorflow h5py pyyaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhh59X9EmPOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout,Activation,Flatten\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Pattern, Set, Tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHb78XHgpgVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set env\n",
        "MODEL_VERSION = 'a'\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/dataset/wikiart'\n",
        "PATH_IMAGES = PATH + '/train'\n",
        "PATH_METADATA = PATH + '/all_data_info.csv'\n",
        "PATH_MODEL = PATH + '/models/m-' + MODEL_VERSION + '.h5'\n",
        "PATH_CHECKPOINT = PATH + '/checkpoints/cp-' + MODEL_VERSION + '.ckpt'\n",
        "CHECKPOINT_PERIOD = 3\n",
        "SLICE_SIZE = 5000\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOyGCFiA9z6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read dataset\n",
        "def read_data():\n",
        "  img_list = []\n",
        "  img_missing_list = []\n",
        "\n",
        "  # metadata\n",
        "  metadata = pd.read_csv(PATH_METADATA)\n",
        "  top_n_classes = metadata.groupby(['style']).style.value_counts().nlargest(NUM_CLASSES).index.get_level_values(0).values.tolist() # get first n classes\n",
        "  metadata = metadata[metadata['style'].isin(top_n_classes)] # filter metadata w.r.t classes\n",
        "  \n",
        "  images_path = metadata['new_filename'].sample(n=SLICE_SIZE, random_state=1).values.tolist()\n",
        "  metadata = metadata[metadata['new_filename'].isin(images_path)] # filter metadata w.r.t slice size\n",
        "\n",
        "  # train_dirs = os.listdir(PATH_IMAGES)\n",
        "  train_dirs = ['train_1', 'train_2']\n",
        "\n",
        "  # read images\n",
        "  for train_dir in train_dirs:\n",
        "    for filename in images_path:\n",
        "        img_path = PATH_IMAGES + '/'+ train_dir + '/' + filename\t\n",
        "        try:\n",
        "          img = image.load_img(img_path, target_size=(224, 224))\n",
        "          x = image.img_to_array(img)\n",
        "          x = np.expand_dims(x, axis=0)\n",
        "          x = preprocess_input(x)\n",
        "          img_list.append(x)\n",
        "        except OSError as e:\n",
        "          # print(\"File not found:\", img_path)\n",
        "          img_missing_list.append(filename)\n",
        "\n",
        "  # convert to float32, fix shape\n",
        "  images = np.array(img_list)\n",
        "  images = images.astype('float32')\n",
        "  images = np.rollaxis(images,1,0)\n",
        "\n",
        "  # remove missing files from metadata\n",
        "  metadata = metadata[~metadata['new_filename'].isin(img_missing_list)] \n",
        "\n",
        "  print(images.shape)\n",
        "  \n",
        "  return images[0], metadata\n",
        "\n",
        "def factorize(metadata):\n",
        "\tmetadata['style_code'] = metadata['style'].astype('category')\n",
        "\tmetadata['style_code'] = pd.factorize(metadata.style_code)[0]\n",
        "\t\n",
        "\treturn metadata\n",
        "\n",
        "def get_categories(labels):\n",
        "\treturn np_utils.to_categorical(labels, NUM_CLASSES)\n",
        "\t\n",
        "def shuffle_data(images, Y):\n",
        "  x, y = shuffle(images, Y, random_state=2)\n",
        "  return train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot8rO625bhf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_init():\n",
        "  #image_input = Input(shape=(224, 224, 3))\n",
        "  model = ResNet50(weights='imagenet', include_top=False)\n",
        "  model.summary()  \n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6K0MYtGbyWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_retrain_classifier(model):\n",
        "  last_layer = model.output\n",
        "  # add a global spatial average pooling layer\n",
        "  x = GlobalAveragePooling2D()(last_layer)\n",
        "  # add fully-connected & dropout layers\n",
        "  x = Dense(512, activation='relu',name='fc-1')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(256, activation='relu',name='fc-2')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  # a softmax layer for n classes\n",
        "  out = Dense(NUM_CLASSES, activation='softmax',name='output_layer')(x)  \n",
        "\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghfbQgTPmcSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_retrained_resnet(model, out):\n",
        "  # # this is the model we will train\n",
        "  model = Model(inputs=model.input, outputs=out)\n",
        "  model.summary()\n",
        "\n",
        "  for layer in model.layers[:-6]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  model.layers[-1].trainable\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])  \n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sysiU7VXdRUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_checkpoints():\n",
        "  checkpoint_dir = os.path.dirname(PATH_CHECKPOINT)\n",
        "\n",
        "  # create checkpount\n",
        "  return ModelCheckpoint(filepath=PATH_CHECKPOINT, save_weights_only=True, verbose=1, period=CHECKPOINT_PERIOD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4TxCyoF5kqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_saved_model():\n",
        "  model = None\n",
        "  \n",
        "  try:\n",
        "    print(\"Model found at: \", PATH_MODEL)\n",
        "  except OSError as e:\n",
        "    print(\"Model doesn't exist\")\n",
        "    \n",
        "  return model\n",
        "\n",
        "def set_weights(model): \n",
        "  try:\n",
        "    model.load_weights(PATH_CHECKPOINT)\n",
        "    print(\"Checkpoint found at: \", PATH_CHECKPOINT)\n",
        "  except OSError as e:\n",
        "    print(\"Checkpoint doesn't exist\")\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww4LbSY5cCFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_create():\n",
        "\n",
        "\tmodel = get_saved_model()\n",
        "\tif model is None:\n",
        "\t\tmodel = resnet_init()\n",
        "\t\tout = resnet_retrain_classifier(model)\n",
        "\t\tmodel = get_retrained_resnet(model, out)\n",
        "\t\n",
        "\tmodel = set_weights(model)\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXEedD6scfHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fit(\n",
        "    model, X_train, y_train, X_test, y_test, cp_callback\n",
        "):\n",
        "  t=time.time()\n",
        "  hist = model.fit(\n",
        "      X_train, y_train, batch_size=32, epochs=12, verbose=1, validation_data=(X_test, y_test), callbacks=[cp_callback]\n",
        "  )\n",
        "  print('Training time: %s' % (t - time.time()))\n",
        "  (loss, accuracy) = model.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "  print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))  \n",
        "\n",
        "  return model, hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQl7w8VbgQyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_visiualize(hist):\n",
        "  \n",
        "  import matplotlib.pyplot as plt\n",
        "  # visualizing losses and accuracy\n",
        "  train_loss=hist.history['loss']\n",
        "  val_loss=hist.history['val_loss']\n",
        "  train_acc=hist.history['acc']\n",
        "  val_acc=hist.history['val_acc']\n",
        "  xc=range(12)\n",
        "\n",
        "  plt.figure(1,figsize=(7,5))\n",
        "  plt.plot(xc,train_loss)\n",
        "  plt.plot(xc,val_loss)\n",
        "  plt.xlabel('num of Epochs')\n",
        "  plt.ylabel('loss')\n",
        "  plt.title('train_loss vs val_loss')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train','val'])\n",
        "  #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "  plt.style.use(['classic'])\n",
        "\n",
        "  plt.figure(2,figsize=(7,5))\n",
        "  plt.plot(xc,train_acc)\n",
        "  plt.plot(xc,val_acc)\n",
        "  plt.xlabel('num of Epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.title('train_acc vs val_acc')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train','val'],loc=4)\n",
        "  #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "  plt.style.use(['classic'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHdhmou6lloa",
        "colab_type": "code",
        "outputId": "5811b2b2-8fca-4d13-93b6-a48a10bdf037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images, metadata = read_data()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 927, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37fSvTHGg1gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata = factorize(metadata)\n",
        "Y = get_categories(metadata.style_code)\n",
        "X_train, X_test, y_train, y_test = shuffle_data(images, Y)\n",
        "\n",
        "model = model_create()\n",
        "cp_callback = set_checkpoints()\n",
        "\n",
        "model, hist = model_fit(\n",
        "    model, X_train, y_train, X_test, y_test, cp_callback\n",
        ")\n",
        "model.save(PATH_MODEL)\n",
        "\n",
        "model_visiualize(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}