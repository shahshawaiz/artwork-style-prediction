{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artwork-style.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNxWA0erb2rla6ihuGZt4hY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahshawaiz/artwork-style-prediction/blob/master/artwork_style.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBt-5EUKJViJ",
        "colab_type": "code",
        "outputId": "c2a05fee-77c0-45a3-925e-d344733a7f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# # activate kaggle, mount grdive, download/unzip dataset\n",
        "# import os\n",
        "# os.environ['KAGGLE_USERNAME'] = \"shahshawaiz\" # username from the json file\n",
        "# os.environ['KAGGLE_KEY'] = \"476e4fb10eef6d9da79358d4df0db985\" # key from the json file\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# files = ['train_1.zip', 'train_2.zip', 'train_3.zip', 'train_4.zip', 'train_5.zip', 'train_6.zip', 'train_7.zip', 'train_8.zip', 'train_9.zip']\n",
        "# for path in files:\n",
        "#   path_dir = path.strip('.zip')\n",
        "#   path_gdrive = '/content/drive/My Drive/Colab Notebooks/dataset/wikiart/train'\n",
        "\n",
        "#   !kaggle competitions download -c painter-by-numbers -f \"$path\"\n",
        "#   !unzip -qq \"$path\"\n",
        "#   !mv -n \"$path_dir\"/ \"$path_gdrive\"/\n",
        "#   !rm -rf \"$path\" \"$path_dir\"\n",
        "\n",
        "# # drive.flush_and_unmount()   \n",
        "\n",
        "# # # # extract zip\n",
        "# # # # !unzip '/content/drive/My Drive/university/s3/lfi/project/data/train_1.zip'\n",
        "\n",
        "# # from tensorflow.python.client import device_lib\n",
        "# # print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6OLjy0AXSAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pkgs installation\n",
        "# !pip install tensorflow h5py pyyaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhh59X9EmPOS",
        "colab_type": "code",
        "outputId": "83261a58-b18a-4478-f80d-a10eda4c7570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout,Activation,Flatten\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, load_model\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Pattern, Set, Tuple"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHb78XHgpgVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set env\n",
        "MODEL_VERSION = 'f'\n",
        "PATH = '/content/drive/My Drive/Colab Notebooks/dataset/wikiart'\n",
        "PATH_IMAGES = PATH + '/train'\n",
        "PATH_VISUALIZE = PATH + '/visualize'\n",
        "PATH_METADATA = PATH + '/all_data_info.csv'\n",
        "PATH_MODEL = PATH + '/models/m-' + MODEL_VERSION + '.h5'\n",
        "PATH_CHECKPOINT = PATH + '/checkpoints/cp-' + MODEL_VERSION + '.ckpt'\n",
        "PATH_MISSING_LOG = PATH + '/missing/ms-' + MODEL_VERSION + '.txt'\n",
        "CHECKPOINT_PERIOD = 3\n",
        "SLICE_SIZE = 10000\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg5F6p44KWed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read dataset\n",
        "def read_data():\n",
        "  img_list = []\n",
        "  img_missing_list = []\n",
        "\n",
        "  # metadata\n",
        "  metadata = pd.read_csv(PATH_METADATA)\n",
        "  print(\"top n: \", metadata.groupby(['style']).style.value_counts().nlargest(NUM_CLASSES))\n",
        "\n",
        "  top_n_classes = metadata.groupby(['style']).style.value_counts().nlargest(NUM_CLASSES).index.get_level_values(0).values.tolist() # get first n classes\n",
        "  metadata = metadata[metadata['style'].isin(top_n_classes)] # filter metadata w.r.t classes  \n",
        "  images_path = metadata['new_filename'].sample(n=SLICE_SIZE, random_state=1).values.tolist()\n",
        "  metadata = metadata[metadata['new_filename'].isin(images_path)] # filter metadata w.r.t slice size\n",
        "\n",
        "  train_dirs = os.listdir(PATH_IMAGES)\n",
        "  # train_dirs = ['train_1', 'train_2']\n",
        "\n",
        "  # read images\n",
        "  for filename in images_path:\n",
        "    image_missing = True\n",
        "\n",
        "    for train_dir in train_dirs:\n",
        "        img_path = PATH_IMAGES + '/'+ train_dir + '/' + filename\t\n",
        "        try:\n",
        "          img = image.load_img(img_path, target_size=(224, 224))\n",
        "          x = image.img_to_array(img)\n",
        "          x = np.expand_dims(x, axis=0)\n",
        "          x = preprocess_input(x)\n",
        "          img_list.append(x)\n",
        "\n",
        "          image_missing = False\n",
        "        except OSError as e:\n",
        "          pass\n",
        "      \n",
        "    if image_missing:\n",
        "      img_missing_list.append(filename)\n",
        "\n",
        "  # convert to float32, fix shape\n",
        "  images = np.array(img_list)\n",
        "  images = images.astype('float32')\n",
        "  images = np.rollaxis(images,1,0)\n",
        "  \n",
        "  # remove missing files from metadata\n",
        "  metadata = metadata[~metadata['new_filename'].isin(img_missing_list)] \n",
        "  \n",
        "  # log missing\n",
        "  np.savetxt(PATH_MISSING_LOG, np.array(img_missing_list), fmt=\"%s\")\n",
        "  \n",
        "  return images[0], metadata\n",
        "\n",
        "def factorize(metadata):\n",
        "\tmetadata['style_code'] = metadata['style'].astype('category')\n",
        "\tmetadata['style_code'] = pd.factorize(metadata.style_code)[0]\n",
        "\t\n",
        "\treturn metadata\n",
        "\n",
        "def get_categories(labels):\n",
        "\treturn np_utils.to_categorical(labels, NUM_CLASSES)\n",
        "\t\n",
        "def shuffle_data(images, Y):\n",
        "  x, y = shuffle(images, Y, random_state=2)\n",
        "  return train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot8rO625bhf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_init():\n",
        "  #image_input = Input(shape=(224, 224, 3))\n",
        "  model = ResNet50(weights='imagenet', include_top=False)\n",
        "  print(model.summary()  )\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6K0MYtGbyWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_retrain_classifier(model):\n",
        "  last_layer = model.output\n",
        "  # add a global spatial average pooling layer\n",
        "  x = GlobalAveragePooling2D()(last_layer)\n",
        "  # add fully-connected & dropout layers\n",
        "  x = Dense(512, activation='relu',name='fc-1')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(256, activation='relu',name='fc-2')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  # a softmax layer for n classes\n",
        "  out = Dense(NUM_CLASSES, activation='softmax',name='output_layer')(x)  \n",
        "\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghfbQgTPmcSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_retrained_resnet(model, out):\n",
        "  # # this is the model we will train\n",
        "  model = Model(inputs=model.input, outputs=out)\n",
        "  \n",
        "  for layer in model.layers[:-6]:\n",
        "    layer.trainable = False\n",
        "\n",
        "  model.layers[-1].trainable\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])  \n",
        "  \n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sysiU7VXdRUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_checkpoints():\n",
        "  checkpoint_dir = os.path.dirname(PATH_CHECKPOINT)\n",
        "\n",
        "  # create checkpount\n",
        "  return ModelCheckpoint(filepath=PATH_CHECKPOINT, save_weights_only=True, verbose=1, period=CHECKPOINT_PERIOD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4TxCyoF5kqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_saved_model():\n",
        "  model = None\n",
        "  \n",
        "  try:\n",
        "    model = load_model(PATH_MODEL)\n",
        "    print(\"Model found at: \", PATH_MODEL)\n",
        "  except OSError as e:\n",
        "    print(\"Model doesn't exist\")\n",
        "    \n",
        "  return model\n",
        "\n",
        "def set_weights(model): \n",
        "  try:\n",
        "    model.load_weights(PATH_CHECKPOINT)\n",
        "    print(\"Checkpoint found at: \", PATH_CHECKPOINT)\n",
        "  except OSError as e:\n",
        "    print(\"Checkpoint doesn't exist\")\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww4LbSY5cCFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_create():\n",
        "\n",
        "\tmodel = get_saved_model()\n",
        "\tif model is None:\n",
        "\t\tmodel = resnet_init()\n",
        "\t\tout = resnet_retrain_classifier(model)\n",
        "\t\tmodel = get_retrained_resnet(model, out)\n",
        "\t\n",
        "\tmodel = set_weights(model)\n",
        " \n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXEedD6scfHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fit(\n",
        "    model, X_train, y_train, X_test, y_test, cp_callback\n",
        "):\n",
        "  t=time.time()\n",
        "  hist = model.fit(\n",
        "      X_train, y_train, batch_size=32, epochs=12, verbose=1, validation_data=(X_test, y_test), callbacks=[cp_callback]\n",
        "  )\n",
        "  print('Training time: %s' % (t - time.time()))\n",
        "  (loss, accuracy) = model.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "  print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))  \n",
        "\n",
        "  return model, hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQl7w8VbgQyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_visiualize(hist):\n",
        "  \n",
        "  import matplotlib.pyplot as plt\n",
        "  # visualizing losses and accuracy\n",
        "  train_loss=hist.history['loss']\n",
        "  val_loss=hist.history['val_loss']\n",
        "  train_acc=hist.history['acc']\n",
        "  val_acc=hist.history['val_acc']\n",
        "  xc=range(12)\n",
        "\n",
        "  plt.figure(1,figsize=(7,5))\n",
        "  plt.plot(xc,train_loss)\n",
        "  plt.plot(xc,val_loss)\n",
        "  plt.xlabel('num of Epochs')\n",
        "  plt.ylabel('loss')\n",
        "  plt.title('train_loss vs val_loss')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train','val'])\n",
        "  #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "  plt.style.use(['classic'])\n",
        "\n",
        "  plt.figure(2,figsize=(7,5))\n",
        "  plt.plot(xc,train_acc)\n",
        "  plt.plot(xc,val_acc)\n",
        "  plt.xlabel('num of Epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.title('train_acc vs val_acc')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train','val'],loc=4)\n",
        "  #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "  plt.style.use(['classic'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHdhmou6lloa",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "3dc084ac-77e8-4c28-c095-78a617ad779a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "images, metadata = read_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top n:  style                 style               \n",
            "Impressionism         Impressionism           10643\n",
            "Realism               Realism                 10523\n",
            "Romanticism           Romanticism              9285\n",
            "Expressionism         Expressionism            7013\n",
            "Post-Impressionism    Post-Impressionism       5778\n",
            "Art Nouveau (Modern)  Art Nouveau (Modern)     4899\n",
            "Baroque               Baroque                  4400\n",
            "Surrealism            Surrealism               4167\n",
            "Symbolism             Symbolism                3476\n",
            "Rococo                Rococo                   2733\n",
            "Name: style, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37fSvTHGg1gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metadata = factorize(metadata)\n",
        "Y = get_categories(metadata.style_code)\n",
        "X_train, X_test, y_train, y_test = shuffle_data(images, Y)\n",
        "\n",
        "cp_callback = set_checkpoints()\n",
        "\n",
        "model = model_create()\n",
        "model, hist = model_fit(\n",
        "    model, X_train, y_train, X_test, y_test, cp_callback\n",
        ")\n",
        "model.save(PATH_MODEL)\n",
        "\n",
        "model_visiualize(hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pue3xTWgeXkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "def visualize_feature(model):\n",
        "  for layer in model.layers:\n",
        "    # check for convolutional layer\n",
        "    if 'res' not in layer.name:\n",
        "      continue\n",
        "\n",
        "    filters, biases = layer.get_weights()\n",
        "\n",
        "    title = layer.name + \" - \" + str(filters.shape).replace(\"'\", '')\n",
        "    print(title)\n",
        "\n",
        "    # normalize filter values to 0-1 so we can visualize them\n",
        "    f_min, f_max = filters.min(), filters.max()\n",
        "    filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "    # plot first few filters\n",
        "    n_filters, ix = 6, 1\n",
        "    for i in range(n_filters):\n",
        "      # get the filter\n",
        "      f = filters[:, :, :, i]\n",
        "      # plot each channel separately\n",
        "      for j in range(5):\n",
        "        # specify subplot and turn of axis\n",
        "        ax = pyplot.subplot(n_filters, 5, ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        # plot filter channel in grayscale\n",
        "        pyplot.imshow(f[:, :, j], cmap='gray')\n",
        "        pyplot.savefig(PATH_VISUALIZE + \"/feature/\" + title + '.png')\n",
        "\n",
        "        ix += 1\n",
        "    # show the figure\n",
        "    pyplot.show()\n",
        "\n",
        "# model.summary()\n",
        "print(visualize_feature(model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kk5SuMEkhFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Model\n",
        "from matplotlib import pyplot\n",
        "from numpy import expand_dims\n",
        "\n",
        "def visualize_featuremap(model):\n",
        "\n",
        "  for layer in model.layers:\n",
        "    # check for convolutional layer\n",
        "    if 'res' not in layer.name:\n",
        "      continue\n",
        "\n",
        "    # redefine model to output right after the first hidden layer\n",
        "    ixs = [2, 5, 9, 13, 17]\n",
        "\n",
        "    outputs = layer.output\n",
        "    outputs = [model.layers[i].output for i in ixs]\n",
        "    model = Model(inputs=model.inputs, outputs=outputs)\n",
        "    # load the image with the required shape\n",
        "    img = load_img(PATH_IMAGES + '/scream.jpg', target_size=(224, 224))\n",
        "    # convert the image to an array\n",
        "    img = img_to_array(img)\n",
        "    # expand dimensions so that it represents a single 'sample'\n",
        "    img = expand_dims(img, axis=0)\n",
        "    # prepare the image (e.g. scale pixel values for the vgg)\n",
        "    img = preprocess_input(img)\n",
        "    # get feature map for first hidden layer\n",
        "    feature_maps = model.predict(img)\n",
        "    # plot the output from each block\n",
        "    square = 5\n",
        "    for fmap in feature_maps:\n",
        "      title = layer.name + \" - \" + str(fmap.shape).replace(\"'\", '')\n",
        "      print(title)\n",
        "\n",
        "      # plot all 64 maps in an 8x8 squares\n",
        "      ix = 1\n",
        "      for _ in range(square):\n",
        "        for _ in range(square):\n",
        "          # specify subplot and turn of axis\n",
        "          ax = pyplot.subplot(square, square, ix)\n",
        "          ax.set_xticks([])\n",
        "          ax.set_yticks([])\n",
        "          # plot filter channel in grayscale\n",
        "          pyplot.imshow(fmap[0, :, :, ix-1], cmap='gray')\n",
        "          pyplot.savefig(PATH_VISUALIZE + \"/feature-map/\" + title + '.png')\n",
        "\n",
        "          ix += 1\n",
        "      # show the figure\n",
        "      pyplot.show()\n",
        "\n",
        "# model.summary()\n",
        "visualize_featuremap(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}